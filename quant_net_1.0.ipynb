{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8273847",
   "metadata": {},
   "source": [
    "# Quant net 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e837629",
   "metadata": {},
   "source": [
    "## Importing the python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e19c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "from torch.utils.data import DataLoader , TensorDataset\n",
    "# from torchvision import datasets, transforms\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Additional Imports\n",
    "import snntorch as snn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#metrics evaluator \n",
    "from sklearn.metrics import classification_report\n",
    "# Set the seed for reproducibility of results\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d11eb2e",
   "metadata": {},
   "source": [
    "## loading the dataset and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b4daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "test_df = pd.read_csv(\"mnist_test.csv\")\n",
    "train_df = pd.read_csv(\"mnist_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cfa5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = test_df.columns\n",
    "label = cols[0]\n",
    "vals  = cols[1:]\n",
    "x_train_temp = train_df[vals]   #.to_numpy()\n",
    "y_train_temp = train_df[label]  #.to_numpy()\n",
    "x_val = torch.tensor(x_train_temp[round(0.8*len(x_train_temp)):].to_numpy() , dtype = torch.float32)\n",
    "y_val = torch.tensor(y_train_temp[round(0.8*len(x_train_temp)):].to_numpy() , dtype = torch.long)\n",
    "x_train = torch.tensor(x_train_temp[:round(0.8*len(x_train_temp))].to_numpy(), dtype = torch.float32)\n",
    "y_train = torch.tensor(y_train_temp[:round(0.8*len(x_train_temp))].to_numpy(), dtype = torch.long)\n",
    "x_test = torch.tensor(test_df[vals].to_numpy(), dtype = torch.float32)\n",
    "y_test = torch.tensor(test_df[label].to_numpy(), dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eafc6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(x_train , y_train)\n",
    "test_dataset = TensorDataset(x_test , y_test)\n",
    "val_dataset = TensorDataset(x_val , y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset , batch_size= 512 , shuffle = True)\n",
    "test_loader = DataLoader(test_dataset , batch_size= 512 , shuffle = True)\n",
    "val_loader = DataLoader(val_dataset , batch_size= 512 , shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d59785",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_2 = {\n",
    "    # SNN\n",
    "    \"threshold1\": 2.3599835635698114,\n",
    "    \"threshold2\": 7.985043705972782,\n",
    "    \"threshold3\": 3.849629060468402,\n",
    "    \"beta\": 0.44154740154430405,\n",
    "    \"num_steps\": 5,\n",
    "\n",
    "    # Network\n",
    "    \"batch_norm\": False,\n",
    "    \"dropout\": 0.3276864426153669,\n",
    "\n",
    "    # Hyper Params\n",
    "    \"lr\": 0.002,\n",
    "\n",
    "    # Early Stopping\n",
    "    \"min_delta\": 1e-6,\n",
    "    \"patience_es\": 3,\n",
    "\n",
    "    # Training\n",
    "    \"epochs\": 100,\n",
    "\n",
    "    #number of quantization \n",
    "    \"n_quant\" : 16,\n",
    "\n",
    "    #precision\n",
    "    \"min\" : -4,\n",
    "\n",
    "    \"max\" : 4\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2463dd69",
   "metadata": {},
   "source": [
    "## definition of submodules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22374173",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = (config_2[\"max\"] - config_2[\"min\"])/config_2[\"n_quant\"]\n",
    "multiplier = pow(10,math.log(1/precision)/math.log(10))\n",
    "class quantize(Function):\n",
    "    @staticmethod \n",
    "    def forward(weight_ref , input):\n",
    "        return torch.round(input.clamp(min=config_2[\"min\"] , max=config_2[\"max\"])*multiplier)/multiplier\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(weight_ref , gradient_out):\n",
    "        gradient_in = gradient_out.clone()\n",
    "        return gradient_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b663cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLinear(nn.Linear):\n",
    "\n",
    "    def forward(self, input):\n",
    "        bin_weights = quantize.apply(self.weight)\n",
    "        if self.bias is None:\n",
    "            return F.linear(input, bin_weights)\n",
    "        else:\n",
    "            return F.linear(input, bin_weights, self.bias)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # Apply Xavier normal initialization\n",
    "        torch.nn.init.xavier_normal_(self.weight)\n",
    "        if self.bias is not None:\n",
    "            # Initialize bias to zero\n",
    "            torch.nn.init.constant_(self.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3685b707",
   "metadata": {},
   "outputs": [],
   "source": [
    "class quant_net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(quant_net, self).__init__()\n",
    "        self.num_steps = 100#config[\"num_steps\"]\n",
    "        self.beta = 0.5 #config[\"beta\"]\n",
    "        self.drop_percent = 0.3 #config[\"dropout\"]\n",
    "\n",
    "        self.quant_fc_1 = BinaryLinear(in_features=28*28 , out_features=128)\n",
    "        self.lif1 = snn.Leaky(beta = 0.5 ,learn_threshold= True , learn_beta= True)\n",
    "        self.quant_fc_2 = BinaryLinear(in_features=128 , out_features=64)\n",
    "        self.lif2 = snn.Leaky(beta = 0.5 ,learn_threshold= True , learn_beta= True)\n",
    "        self.quant_fc_3 = BinaryLinear(in_features=64 , out_features=32)\n",
    "        self.lif3 = snn.Leaky(beta = 0.5 ,learn_threshold= True , learn_beta= True)\n",
    "        self.quant_fc_4 = BinaryLinear(in_features=32 , out_features=10)\n",
    "        self.lif4 = snn.Leaky(beta = 0.5 ,learn_threshold= True , learn_beta= True)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self , input):\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "        mem4 = self.lif4.init_leaky()\n",
    "\n",
    "        spike4_rec = []\n",
    "        mem4_rec = []\n",
    "\n",
    "        for step in range(self.num_steps):\n",
    "            \n",
    "            val_1 = self.quant_fc_1(input)\n",
    "            spike1 , mem1 = self.lif1(val_1,mem1)\n",
    "            \n",
    "            spike1 = self.dropout(spike1)\n",
    "            val_2 = self.quant_fc_2(spike1)\n",
    "            spike2 , mem2 = self.lif2(val_2,mem2)\n",
    "\n",
    "            val_3 = self.quant_fc_3(spike2)\n",
    "            spike3 , mem3 = self.lif3(val_3,mem3)\n",
    "\n",
    "            spike3 = self.dropout(spike3)\n",
    "            val_4 = self.quant_fc_4(spike3)\n",
    "            spike4 , mem4 = self.lif4(val_4,mem4)\n",
    "\n",
    "            spike4_rec.append(spike4)\n",
    "            mem4_rec.append(mem4)\n",
    "\n",
    "        return torch.stack(spike4_rec , dim = 0) , torch.stack(mem4_rec , dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=config_2[\"patience_es\"], min_delta=config_2[\"min_delta\"]):\n",
    "        # Early stops the training if validation loss doesn't improve after a given patience.\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_loss\n",
    "        elif val_loss > self.best_score - self.min_delta:\n",
    "            self.counter += 1\n",
    "            print(f\"Earlystop {self.counter}/{self.patience}\\n\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_loss\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92e3e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = quant_net().to(device)\n",
    "\n",
    "# Optimizer and Loss Function\n",
    "optimizer = Adam(model.parameters(), lr=config_2[\"lr\"])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(patience=config_2[\"patience_es\"], min_delta=config_2[\"min_delta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fd8329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for data, targets in train_loader:\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        spike_out, _ = model(data)\n",
    "        output = spike_out.sum(dim=0)\n",
    "        loss = criterion(output, targets)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted_train = torch.max(output.data, 1)\n",
    "        total_train += targets.size(0)\n",
    "        correct_train += (predicted_train == targets).sum().item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbebb88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in val_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            spike_out, _ = model(data)\n",
    "            output = spike_out.sum(dim=0)\n",
    "            loss = criterion(output, targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted_val = torch.max(output.data, 1)\n",
    "            total_val += targets.size(0)\n",
    "            correct_val += (predicted_val == targets).sum().item()\n",
    "\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c93cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_accuracies, val_losses, val_accuracies = [], [], [], []\n",
    "best_val_accuracy = 0\n",
    "model_path = \"updated_best_BSNN_model.pth\"\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "for epoch in range(config_2[\"epochs\"]):\n",
    "    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    val_loss, val_accuracy = validate(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}, Training Loss: {train_loss:.5f}, Training Accuracy: {train_accuracy:.2f}%, Validation Loss: {val_loss:.5f}, Validation Accuracy: {val_accuracy:.2f}%\\n\")\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"Saved model with improved validation accuracy: {val_accuracy:.2f}% \\n\")\n",
    "\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"\\nEarly stopping triggered\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceca8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training, validation, and test losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plotting training, validation, and test accuracies\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566085bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion, device, model_path=\"best_BSNN_model.pth\"):\n",
    "\n",
    "    # Initialize variables for test loss and accuracy\n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "\n",
    "    # Restore best BSNN Model\n",
    "    if os.path.isfile(model_path):\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        print(f\"Loaded saved model from {model_path}\\n\")\n",
    "\n",
    "    # Switch model to evaluation mode\n",
    "    model.eval()\n",
    "    predicted_lst = torch.empty(0)\n",
    "    target_lst = torch.empty(0)\n",
    "\n",
    "    # Iterate over the test data\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs, _ = model(data)  # Modify according to your model's output\n",
    "            outputs = outputs.mean(dim=0)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += targets.size(0)\n",
    "            predicted_lst = torch.cat((predicted_lst , predicted.cpu()) , dim = 0)\n",
    "            target_lst = torch.cat((target_lst , targets.cpu()) , dim = 0)\n",
    "            \n",
    "            correct_test += (predicted == targets).sum().item()\n",
    "\n",
    "    # Calculate average loss and accuracy\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = 100 * correct_test / total_test\n",
    "\n",
    "    print(classification_report(predicted_lst , target_lst))\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71387209",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = test(model, val_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
